{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chroma\n",
    "\n",
    "Chroma is Ai-native open- source vector database focused on developer productivity and happiness. chroma is licensed under Apache 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### building a simple vectordb\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content=\"Today, I want to highlight a crucial element in the success of machine learning \\napplications: data ingestion, particularly within the LangChain framework.\\n\\nData ingestion is the foundation that enables our language models to thrive. \\nIt involves the systematic collection and preparation of data from various sources, ensuring that our models receive high-quality, relevant information. \\nIn the context of LangChain, this process is vital for transforming raw data into actionable insights.\\n\\nWhy is data ingestion so important? First, the quality of the data directly influences the model's performance. \\nBy providing diverse and accurate datasets, we empower our models to generate meaningful responses and understand context effectively. \\nFurthermore, as we scale our applications, efficient data ingestion becomes essential. LangChain offers robust tools and integrations to simplify this process, allowing developers to automate data flows seamlessly.\\n\\nIn conclusion, prioritizing effective data ingestion not only enhances the capabilities of our language models but also leads to more impactful applications. \\nBy leveraging the tools available in LangChain, we can unlock the full potential of our data and deliver exceptional user experiences.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader= TextLoader(\"speech.txt\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##split\n",
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=0)\n",
    "splits= text_spliter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayan\\AppData\\Local\\Temp\\ipykernel_25240\\3368680621.py:1: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding = OllamaEmbeddings()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x28fa76bde40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = OllamaEmbeddings()\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Today, I want to highlight a crucial element in the success of machine learning \\napplications: data ingestion, particularly within the LangChain framework.\\n\\nData ingestion is the foundation that enables our language models to thrive. \\nIt involves the systematic collection and preparation of data from various sources, ensuring that our models receive high-quality, relevant information. \\nIn the context of LangChain, this process is vital for transforming raw data into actionable insights.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### qurey it\n",
    "\n",
    "qurey = \"is data ingestion so important? First, the quality\"\n",
    "docs= vectordb.similarity_search(qurey)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###save to the desk \n",
    "\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embedding, persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today, I want to highlight a crucial element in the success of machine learning \n",
      "applications: data ingestion, particularly within the LangChain framework.\n",
      "\n",
      "Data ingestion is the foundation that enables our language models to thrive. \n",
      "It involves the systematic collection and preparation of data from various sources, ensuring that our models receive high-quality, relevant information. \n",
      "In the context of LangChain, this process is vital for transforming raw data into actionable insights.\n"
     ]
    }
   ],
   "source": [
    "db2 = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding)\n",
    "docs = db2.similarity_search(qurey)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'speech.txt'}, page_content='Today, I want to highlight a crucial element in the success of machine learning \\napplications: data ingestion, particularly within the LangChain framework.\\n\\nData ingestion is the foundation that enables our language models to thrive. \\nIt involves the systematic collection and preparation of data from various sources, ensuring that our models receive high-quality, relevant information. \\nIn the context of LangChain, this process is vital for transforming raw data into actionable insights.'),\n",
       "  19838.82554154424),\n",
       " (Document(metadata={'source': 'speech.txt'}, page_content='In conclusion, prioritizing effective data ingestion not only enhances the capabilities of our language models but also leads to more impactful applications. \\nBy leveraging the tools available in LangChain, we can unlock the full potential of our data and deliver exceptional user experiences.'),\n",
       "  27097.61618238708),\n",
       " (Document(metadata={'source': 'speech.txt'}, page_content=\"Why is data ingestion so important? First, the quality of the data directly influences the model's performance. \\nBy providing diverse and accurate datasets, we empower our models to generate meaningful responses and understand context effectively. \\nFurthermore, as we scale our applications, efficient data ingestion becomes essential. LangChain offers robust tools and integrations to simplify this process, allowing developers to automate data flows seamlessly.\"),\n",
       "  28798.853250422973)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### similarity search with score\n",
    "\n",
    "docs= vectordb.similarity_search_with_score(qurey)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Today, I want to highlight a crucial element in the success of machine learning \\napplications: data ingestion, particularly within the LangChain framework.\\n\\nData ingestion is the foundation that enables our language models to thrive. \\nIt involves the systematic collection and preparation of data from various sources, ensuring that our models receive high-quality, relevant information. \\nIn the context of LangChain, this process is vital for transforming raw data into actionable insights.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### REtreriver option\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever.invoke(qurey)[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
